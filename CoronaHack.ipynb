{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoronaHack.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzGMXBn89+CuB2EhUhjr+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NirobxHasan/COVID-19_Detection_from_Chest_X-Ray_Images/blob/main/CoronaHack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGowmxSR7x4f"
      },
      "source": [
        "%matplotlib inline\r\n",
        "%config InlineBackend.figure_format = 'retina'\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import torch\r\n",
        "from torchvision import datasets, transforms\r\n",
        "\r\n",
        "import helper\r\n",
        "!wget https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/3bd7dea850e936d8cb44adda8200e4e2b5d627e3/intro-to-pytorch/helper.py\r\n",
        "import importlib\r\n",
        "importlib.reload(helper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUobAS7t8N43"
      },
      "source": [
        "#install depenencies\r\n",
        "!pip install kaggle\r\n",
        "#upload the credentials of the kaggle account, which is j JSON file.\r\n",
        "from google.colab import files\r\n",
        "files.upload()\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "# Give permissions to avoids a warning on Kaggle tool startup.\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3HrQ88a8nAX"
      },
      "source": [
        "!kaggle datasets download -d praveengovi/coronahack-chest-xraydataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62Mp7V26843F"
      },
      "source": [
        "!unzip coronahack-chest-xraydataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBL2pTx7RHQ1"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foSWaTRq9THN"
      },
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "import time\r\n",
        "import shutil\r\n",
        "\r\n",
        "PATH_TRAIN = \"/content/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/\"\r\n",
        "TOTAL_IMGS = len(os.listdir(PATH_TRAIN))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebPhTi0TtNVG"
      },
      "source": [
        "import pandas as pd\r\n",
        "data = pd.read_csv(\"/content/Chest_xray_Corona_Metadata.csv\")\r\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtJ95uvkuEoo"
      },
      "source": [
        "# Printing unique labels\r\n",
        "unique_labels = []\r\n",
        "for i in  data['Label']:\r\n",
        "    if i not in unique_labels:\r\n",
        "        unique_labels.append(i)\r\n",
        "        \r\n",
        "print(unique_labels)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp3ikaOnugQd"
      },
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "import time\r\n",
        "import shutil\r\n",
        "\r\n",
        "PATH_TRAIN = \"/content/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train\"\r\n",
        "TOTAL_IMGS = len(os.listdir(PATH_TRAIN))\r\n",
        "normal = 0\r\n",
        "infected = 0\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "img = data[\"X_ray_image_name\"]\r\n",
        "label = data[\"Label\"]\r\n",
        "image_type = data[\"Dataset_type\"]\r\n",
        "all_dir = os.listdir(PATH_TRAIN)\r\n",
        "\r\n",
        "os.mkdir(\"train\")\r\n",
        "os.mkdir('train/INFECTED')\r\n",
        "os.mkdir(\"train/NORMAL\")\r\n",
        "\r\n",
        "wrong_info = 0  # Checking if the provided list maps the images correctly\r\n",
        "\r\n",
        "# Moving the train images to designated folders\r\n",
        "\r\n",
        "for i in range(len(image_type)):\r\n",
        "    if image_type[i] == \"TRAIN\":\r\n",
        "        if img[i] in all_dir: # Make sure that all images in Chest_xray_Corona_Metadata.csv is mapped\r\n",
        "            if label[i] == \"Normal\":\r\n",
        "                infected = infected + 1\r\n",
        "                shutil.copy(\r\n",
        "                    PATH_TRAIN + \"/\" + img[i], \"train/NORMAL/\" + img[i]\r\n",
        "                )\r\n",
        "                normal = normal + 1\r\n",
        "\r\n",
        "            else:\r\n",
        "\r\n",
        "                shutil.copy(\r\n",
        "                    PATH_TRAIN + \"/\" + img[i], \"train/INFECTED/\" + img[i]\r\n",
        "                )\r\n",
        "                infected = infected + 1\r\n",
        "\r\n",
        "        else:\r\n",
        "            wrong_info = wrong_info + 1\r\n",
        "\r\n",
        "print(\r\n",
        "    \"X-ray of Normal patients (TRAIN DATASET): \" + str(normal),\r\n",
        "    \"X-ray of Infected patients (TRAIN DATASET): \" + str(infected),\r\n",
        "    end = \"\\n\"\r\n",
        ")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoiE1ugD1jXK"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "fig = plt.figure()\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "categories = [\"NORMAL\", \"INFECTED\"]\r\n",
        "number_of_imgs = [normal, infected]\r\n",
        "ax.bar(0, number_of_imgs[0], color=\"g\", width=0.1)\r\n",
        "ax.bar(0.15, number_of_imgs[1], color=\"r\", width=0.1)\r\n",
        "ax.legend(labels=categories)\r\n",
        "ax.set_ylabel(\"Number of images\")\r\n",
        "ax.set_xlabel(\"Categories\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrpUzCss1niF"
      },
      "source": [
        "PATH_TEST = \"/content/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test\"\r\n",
        "TOTAL_IMGS = len(os.listdir(PATH_TEST))\r\n",
        "normal = 0\r\n",
        "infected = 0\r\n",
        "\r\n",
        "img = data[\"X_ray_image_name\"]\r\n",
        "label = data[\"Label\"]\r\n",
        "image_type = data[\"Dataset_type\"]\r\n",
        "all_dir = os.listdir(PATH_TEST)\r\n",
        "\r\n",
        "os.mkdir(\"test\")\r\n",
        "os.mkdir('test/INFECTED')\r\n",
        "os.mkdir(\"test/NORMAL\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "wrong_info = 0\r\n",
        "\r\n",
        "for i in range(len(image_type)):\r\n",
        "    if image_type[i] == \"TEST\":\r\n",
        "        if img[i] in all_dir:\r\n",
        "            if label[i] == \"Normal\":\r\n",
        "                infected = infected + 1\r\n",
        "                shutil.copy(\r\n",
        "                    PATH_TEST + \"/\" + img[i], \"test/NORMAL/\" + img[i]\r\n",
        "                )\r\n",
        "                normal = normal + 1\r\n",
        "\r\n",
        "            else:\r\n",
        "\r\n",
        "                shutil.copy(\r\n",
        "                    PATH_TEST + \"/\" + img[i], \"test/INFECTED/\" + img[i]\r\n",
        "                )\r\n",
        "                infected = infected + 1\r\n",
        "\r\n",
        "        else:\r\n",
        "            wrong_info = wrong_info + 1\r\n",
        "\r\n",
        "print(\r\n",
        "    \"X-ray of Normal patients (TEST DATASET): \" + str(normal),\r\n",
        "    \"X-ray of Infected patients (TEST DATASET): \" + str(infected),\r\n",
        "    end = \"\\n\"\r\n",
        ")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDgkFGXh2sNW"
      },
      "source": [
        "fig = plt.figure()\r\n",
        "ax = fig.add_axes([0, 0, 1, 1])\r\n",
        "categories = [\"NORMAL\", \"INFECTED\"]\r\n",
        "number_of_imgs = [normal, infected]\r\n",
        "ax.bar(0, number_of_imgs[0], color=\"g\", width=0.1)\r\n",
        "ax.bar(0.15, number_of_imgs[1], color=\"r\", width=0.1)\r\n",
        "ax.legend(labels=categories)\r\n",
        "ax.set_ylabel(\"Number of images\")\r\n",
        "ax.set_xlabel(\"Categories\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl00JMVO2_kV"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "def list_files(startpath):\r\n",
        "    for root, dirs, files in os.walk(startpath):\r\n",
        "        level = root.replace(startpath, '').count(os.sep)\r\n",
        "        indent = ' ' * 4 * (level)\r\n",
        "        print('{}{}/'.format(indent, os.path.basename(root)))\r\n",
        "        subindent = ' ' * 4 * (level + 1)\r\n",
        "        n = 0\r\n",
        "        for f in files:\r\n",
        "            n = n+1\r\n",
        "            if n>5:\r\n",
        "                print('{}{}'.format(subindent, f),end = \"  ...... \\n\")\r\n",
        "                break\r\n",
        "            print('{}{}'.format(subindent, f))\r\n",
        "\r\n",
        "\r\n",
        "list_files(\"/content/Coronahack-Chest-XRay-Dataset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEYDiebU3Z6T"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import os\r\n",
        "import time\r\n",
        "import torchvision\r\n",
        "from PIL import ImageFile\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq4OglRD3hx7"
      },
      "source": [
        "ImageFile.LOAD_TRUNCATED_IMAGES = True # To prevent error during loading broken images\r\n",
        "\r\n",
        "PATH_TRAIN = \"train\"\r\n",
        "PATH_TEST  = \"test\"\r\n",
        "EPOCHS = 10\r\n",
        "BATCH_SIZE = 32\r\n",
        "TOTAL_SIZE = len(os.listdir(PATH_TRAIN + \"/NORMAL\")) + len(\r\n",
        "    os.listdir(PATH_TRAIN + \"/INFECTED\")\r\n",
        ")\r\n",
        "TOTAL_TEST_SIZE = len(os.listdir(PATH_TEST + \"/NORMAL\")) + len(\r\n",
        "    os.listdir(PATH_TEST + \"/INFECTED\")\r\n",
        ")\r\n",
        "STEPS_PER_EPOCH = TOTAL_SIZE // BATCH_SIZE\r\n",
        "STEPS_PER_TEST_EPOCH = TOTAL_TEST_SIZE // BATCH_SIZE\r\n",
        "IMAGE_H, IMAGE_W = 224, 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-iFyu7w3mcz"
      },
      "source": [
        "transform = torchvision.transforms.Compose(\r\n",
        "    [  # Applying Augmentation\r\n",
        "        torchvision.transforms.Resize((IMAGE_H, IMAGE_W)),\r\n",
        "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\r\n",
        "        torchvision.transforms.RandomVerticalFlip(p=0.5),\r\n",
        "        torchvision.transforms.RandomRotation(30),\r\n",
        "        torchvision.transforms.ToTensor(),\r\n",
        "        torchvision.transforms.Normalize(\r\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] # 0-1 to [-1,1] , formula (x-mean)/std\r\n",
        "        ),\r\n",
        "    ]\r\n",
        ")  # Normalizing data\r\n",
        "\r\n",
        "# Intitalizing the train data loader and applying the transformations\r\n",
        "\r\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=PATH_TRAIN, transform=transform)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    train_dataset, batch_size=BATCH_SIZE, num_workers=1, shuffle=True\r\n",
        ")\r\n",
        "\r\n",
        "# Intitalizing the test data loader\r\n",
        "\r\n",
        "valid_dataset = torchvision.datasets.ImageFolder(\r\n",
        "    root=PATH_TEST, transform=transform\r\n",
        ")\r\n",
        "\r\n",
        "valid_loader = torch.utils.data.DataLoader(\r\n",
        "    valid_dataset, batch_size=BATCH_SIZE, num_workers=1, shuffle=True\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppC8sd623syj"
      },
      "source": [
        "images, labels = next(iter(train_loader))\r\n",
        "images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZw-9duEr084"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8JUBH0bxvqM"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# check if CUDA is available\r\n",
        "train_on_gpu = torch.cuda.is_available()\r\n",
        "\r\n",
        "if not train_on_gpu:\r\n",
        "    print('CUDA is not available.  Training on CPU ...')\r\n",
        "else:\r\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7UsIfExs4Gh"
      },
      "source": [
        "# #CNN network\r\n",
        "# class Net(nn.Module):\r\n",
        "#     def __init__(self,num_classes=2):\r\n",
        "#         super(Net,self).__init__()\r\n",
        "        \r\n",
        "#         #Output size after convolution filter\r\n",
        "#         #((w-f+2P)/s) +1\r\n",
        "        \r\n",
        "#         #Input shape= (32, 3, 224, 224)\r\n",
        "        \r\n",
        "#         self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\r\n",
        "#         #Shape= (256,12,224,224)\r\n",
        "#         # self.bn1=nn.BatchNorm2d(num_features=12)\r\n",
        "#         #Shape= (256,12,224,224)\r\n",
        "#         self.relu1=nn.ReLU()\r\n",
        "#         #Shape= (256,12,224,224)\r\n",
        "        \r\n",
        "#         self.pool=nn.MaxPool2d(kernel_size=2)\r\n",
        "#         #Reduce the image size be factor 2\r\n",
        "#         #Shape= (256,12,112,112)\r\n",
        "        \r\n",
        "        \r\n",
        "#         self.conv2=nn.Conv2d(in_channels=12,out_channels=24,kernel_size=3,stride=1,padding=1)\r\n",
        "#         #Shape= (256,20,112,112)\r\n",
        "#         self.relu2=nn.ReLU()\r\n",
        "#         #Shape= (256,20,112,112)\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "#         self.conv3=nn.Conv2d(in_channels=24,out_channels=64,kernel_size=3,stride=1,padding=1)\r\n",
        "#         #Shape= (256,32,112,112)\r\n",
        "#         # self.bn3=nn.BatchNorm2d(num_features=64)\r\n",
        "#         #Shape= (256,32,112,112)\r\n",
        "#         self.relu3=nn.ReLU()\r\n",
        "#         #Shape= (256,32,112,112)\r\n",
        "        \r\n",
        "        \r\n",
        "#         self.fc1=nn.Linear(112 * 112 * 64, 500)\r\n",
        "#         self.fc2=nn.Linear(500,out_features=num_classes)\r\n",
        "        \r\n",
        "#         self.dropout = nn.Dropout(0.25)\r\n",
        "        \r\n",
        "#         #Feed forwad function\r\n",
        "        \r\n",
        "#     def forward(self,input):\r\n",
        "#         output=self.conv1(input)\r\n",
        "#         # output=self.bn1(output)\r\n",
        "#         output=self.relu1(output)\r\n",
        "            \r\n",
        "#         output=self.pool(output)\r\n",
        "            \r\n",
        "#         output=self.conv2(output)\r\n",
        "#         output=self.relu2(output)\r\n",
        "            \r\n",
        "#         output=self.conv3(output)\r\n",
        "#         # output=self.bn3(output)\r\n",
        "#         output=self.relu3(output)\r\n",
        "            \r\n",
        "            \r\n",
        "#             #Above output will be in matrix form, with shape (256,32,75,75)\r\n",
        "            \r\n",
        "#         output=output.view(-1,64*112*112)\r\n",
        "            \r\n",
        "#         output = self.dropout(output)\r\n",
        "#         output=F.relu(self.fc1(output))\r\n",
        "#         output = self.dropout(output)\r\n",
        "#         output=self.fc2(output)\r\n",
        "            \r\n",
        "#         return output\r\n",
        "# model = Net()\r\n",
        "# print(model)\r\n",
        "\r\n",
        "# # move tensors to GPU if CUDA is available\r\n",
        "# if train_on_gpu:\r\n",
        "#     model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wt5B_3excld"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWcCha7KLXF0"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        # convolutional layer\r\n",
        "        self.conv1 = nn.Conv2d(3, 16, 5)\r\n",
        "        # max pooling layer\r\n",
        "        self.pool = nn.MaxPool2d(2, 2)\r\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5)\r\n",
        "        self.dropout = nn.Dropout(0.2)\r\n",
        "        self.fc1 = nn.Linear(32*53*53, 256)\r\n",
        "        self.fc2 = nn.Linear(256, 84)\r\n",
        "        self.fc3 = nn.Linear(84, 2)\r\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        # add sequence of convolutional and max pooling layers\r\n",
        "        x = self.pool(F.relu(self.conv1(x)))\r\n",
        "        x = self.pool(F.relu(self.conv2(x)))\r\n",
        "        x = self.dropout(x)\r\n",
        "        x = x.view(-1, 32 * 53 * 53)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\r\n",
        "        x = self.softmax(self.fc3(x))\r\n",
        "        return x\r\n",
        "model = Net()\r\n",
        "print(model)\r\n",
        "\r\n",
        "# move tensors to GPU if CUDA is available\r\n",
        "if train_on_gpu:\r\n",
        "    model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KhW3zgwwus1"
      },
      "source": [
        "# model=ConvNet(num_classes=2).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aALP9WXAw0Ez"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "# specify loss function (categorical cross-entropy)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# specify optimizer\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_jIUzfzxHJL"
      },
      "source": [
        "# number of epochs to train the model\r\n",
        "n_epochs = 20\r\n",
        "\r\n",
        "valid_loss_min = np.Inf # track change in validation loss\r\n",
        "train_losses, test_losses = [], []\r\n",
        "for epoch in range(1, n_epochs+1):\r\n",
        "\r\n",
        "    # keep track of training and validation loss\r\n",
        "  \r\n",
        "    train_loss = 0.0\r\n",
        "    valid_loss = 0.0\r\n",
        "    \r\n",
        "    ###################\r\n",
        "    # train the model #\r\n",
        "    ###################\r\n",
        "    model.train()\r\n",
        "    for data, target in train_loader:\r\n",
        "        # move tensors to GPU if CUDA is available\r\n",
        "        if train_on_gpu:\r\n",
        "            data, target = data.cuda(), target.cuda()\r\n",
        "        # clear the gradients of all optimized variables\r\n",
        "        optimizer.zero_grad()\r\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\r\n",
        "        output = model(data)\r\n",
        "        # calculate the batch loss\r\n",
        "        loss = criterion(output, target)\r\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\r\n",
        "        loss.backward()\r\n",
        "        # perform a single optimization step (parameter update)\r\n",
        "        optimizer.step()\r\n",
        "        # update training loss\r\n",
        "        train_loss += loss.item()*data.size(0)\r\n",
        "        \r\n",
        "    ######################    \r\n",
        "    # validate the model #\r\n",
        "    ######################\r\n",
        "    accuracy = 0 \r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    for data, target in valid_loader:\r\n",
        "        # move tensors to GPU if CUDA is available\r\n",
        "        if train_on_gpu:\r\n",
        "            data, target = data.cuda(), target.cuda()\r\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\r\n",
        "        output = model(data)\r\n",
        "        # calculate the batch loss\r\n",
        "        loss = criterion(output, target)\r\n",
        "        # update average validation loss \r\n",
        "        valid_loss += loss.item()*data.size(0)\r\n",
        "\r\n",
        "        ps = torch.exp(output)\r\n",
        "        top_p,top_class = ps.topk(1, dim=1)\r\n",
        "        equals = top_class == target.view(*top_class.shape).cuda()\r\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\r\n",
        "     \r\n",
        "    \r\n",
        "    # calculate average losses\r\n",
        "    train_loss = train_loss/len(train_loader.sampler)\r\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\r\n",
        "\r\n",
        "    train_losses.append(train_loss)\r\n",
        "    test_losses.append(valid_loss)\r\n",
        "\r\n",
        "\r\n",
        "    # # print training/validation statistics \r\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t Test Accuracy: {:.3f}'.format(\r\n",
        "        epoch, train_loss, valid_loss,accuracy/len(valid_loader)))\r\n",
        "    \r\n",
        "    # save model if validation loss has decreased\r\n",
        "    if valid_loss <= valid_loss_min:\r\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\r\n",
        "        valid_loss_min,\r\n",
        "        valid_loss))\r\n",
        "        torch.save(model.state_dict(), 'CoronaHack_2layer.pth')\r\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1PUUAR3roIt"
      },
      "source": [
        "plt.plot(train_losses, label='Training loss')\r\n",
        "plt.plot(test_losses, label='Validation loss')\r\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7hcPez2tiux"
      },
      "source": [
        "Resnet18 implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4_nzFID_M7A"
      },
      "source": [
        "model_ft = torchvision.models.resnet18(False)  # Initializing resnet18\r\n",
        "model_ft.load_state_dict(torch.load(\"/content/resnet18-5c106cde.pth\"))\r\n",
        "num_ftrs = model_ft.fc.in_features # Getting last layer's output features\r\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2) # Modifying the last layer accordng to our need"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a72WU58_IsFN"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "model_ft.to(device)  # Sending model to device\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(\r\n",
        "    model_ft.parameters(), lr=0.0007\r\n",
        ")  # lr should be kept low so that the pre-trained weights don't change easily"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElUhBe3LIx-M"
      },
      "source": [
        "def get_test():\r\n",
        "    test_loss = []\r\n",
        "    correct = 0\r\n",
        "    incorrect = 0\r\n",
        "\r\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "    for batch_idx, (data, target) in enumerate(valid_loader):\r\n",
        "        if batch_idx == STEPS_PER_TEST_EPOCH:\r\n",
        "            break\r\n",
        "\r\n",
        "       \r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "\r\n",
        "            data = data.to(device)\r\n",
        "            target = target.long().to(device)\r\n",
        "            output = model_ft(data)\r\n",
        "            criterion = nn.CrossEntropyLoss()\r\n",
        "            loss = criterion(output, target)\r\n",
        "\r\n",
        "            \r\n",
        "\r\n",
        "            for i in range(BATCH_SIZE):\r\n",
        "                a = []\r\n",
        "                for j in output[i]:\r\n",
        "                    a.append(float(j.detach()))\r\n",
        "\r\n",
        "                pred = a.index(max(a))\r\n",
        "\r\n",
        "                if pred == int(target[i]):\r\n",
        "                    correct = correct + 1\r\n",
        "\r\n",
        "                else:\r\n",
        "                    incorrect = incorrect + 1\r\n",
        "\r\n",
        "        test_loss.append(float(loss.detach()))\r\n",
        "    print(\"CORRECT: \" + str(correct), \"INCORRECT: \" + str(incorrect),\"TEST ACCURACY: \"+str(correct/(correct+incorrect)))\r\n",
        "    return (\r\n",
        "            correct/(incorrect+correct),\r\n",
        "            sum(test_loss)/len(test_loss),\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_usRCONxJVJ7"
      },
      "source": [
        "acc_ , loss_ = get_test()\r\n",
        "print(\"ACCURACY AND LOSS BEFORE TUNING\")\r\n",
        "print(\"ACCURACY : \"+str(acc_),\"LOSS : \"+str(loss_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik9P1ajYJ0lf"
      },
      "source": [
        "avg_test_loss_history = []\r\n",
        "avg_test_accuracy_history = []\r\n",
        "avg_train_loss_history = []\r\n",
        "avg_train_accuracy_history = []\r\n",
        "\r\n",
        "loss_history = []\r\n",
        "accuracy_history = []\r\n",
        "\r\n",
        "new_best = 0\r\n",
        "\r\n",
        "for i in range(EPOCHS):\r\n",
        "\r\n",
        "    start = time.time()\r\n",
        "    print(\r\n",
        "        \"-----------------------EPOCH \"\r\n",
        "        + str(i)\r\n",
        "        + \" -----------------------------------\"\r\n",
        "    )\r\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\r\n",
        "        if batch_idx == STEPS_PER_EPOCH:\r\n",
        "            break\r\n",
        "        optimizer.zero_grad()  # Resetting gradients after each optimizations\r\n",
        "        # Sending input , target to device\r\n",
        "        data = data.to(device) \r\n",
        "        target = target.to(device)\r\n",
        "        output = model_ft(data)\r\n",
        "        loss = criterion(output, target.reshape((BATCH_SIZE,)).long())\r\n",
        "        loss_history.append(loss.detach())\r\n",
        "       \r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()  # Optimizing the model\r\n",
        "\r\n",
        "        # Checking train accuracy\r\n",
        "\r\n",
        "        correct = 0\r\n",
        "        incorrect = 0\r\n",
        "        for p in range(BATCH_SIZE):\r\n",
        "            a = []\r\n",
        "            for j in output[p]:\r\n",
        "                a.append(float(j.detach()))\r\n",
        "\r\n",
        "            pred = a.index(max(a))\r\n",
        "\r\n",
        "            if pred == int(target[p]):\r\n",
        "                correct = correct + 1\r\n",
        "\r\n",
        "            else:\r\n",
        "\r\n",
        "                incorrect = incorrect + 1\r\n",
        "\r\n",
        "        print(\r\n",
        "            \"\\r EPOCH \"\r\n",
        "            + str(i)\r\n",
        "            + \" MINIBATCH: \"\r\n",
        "            + str(batch_idx)\r\n",
        "            + \"/\"\r\n",
        "            + str(STEPS_PER_EPOCH)\r\n",
        "            + \" LOSS: \"\r\n",
        "            + str(loss_history[-1]),\r\n",
        "            end = \"\"\r\n",
        "            \r\n",
        "        )\r\n",
        "        \r\n",
        "        accuracy_history.append(correct/(correct+incorrect))\r\n",
        "\r\n",
        "    end = time.time()\r\n",
        "    print(\r\n",
        "        \" \\n EPOCH \"\r\n",
        "        + str(i)\r\n",
        "        + \" LOSS \"\r\n",
        "        + str(sum(loss_history[-STEPS_PER_EPOCH:]) / STEPS_PER_EPOCH)\r\n",
        "        + \" ETA: \"\r\n",
        "        + str(end - start)\r\n",
        "        + \" \\n MAX LOSS: \"\r\n",
        "        + str(max(loss_history[-STEPS_PER_EPOCH:]))\r\n",
        "        + \" MIN LOSS: \"\r\n",
        "        + str(min(loss_history[-STEPS_PER_EPOCH:]))\r\n",
        "        + \" TRAIN ACCURACY: \"\r\n",
        "        + str(sum(accuracy_history[-STEPS_PER_EPOCH:]) / STEPS_PER_EPOCH)\r\n",
        "    )\r\n",
        "    \r\n",
        "    avg_train_loss_history.append(sum(loss_history[-STEPS_PER_EPOCH:]) / STEPS_PER_EPOCH)\r\n",
        "    avg_train_accuracy_history.append(sum(accuracy_history[-STEPS_PER_EPOCH:]) / STEPS_PER_EPOCH)\r\n",
        "    \r\n",
        "    test_acc , test_loss  = get_test()\r\n",
        "    \r\n",
        "    avg_test_accuracy_history.append(test_acc)\r\n",
        "    avg_train_loss_history.append(test_loss)\r\n",
        "    \r\n",
        "    if test_acc>new_best: \r\n",
        "        new_best = test_acc\r\n",
        "        torch.save(model_ft.state_dict(), \"model_resnet18.pth\") # Saving our best model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-lupbaPQs_y"
      },
      "source": [
        "model_ft.load_state_dict(torch.load('model_resnet18.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsRBFFBYQ2N7"
      },
      "source": [
        "print(\"ACCURACY : \",new_best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CvwBfjMLxAa"
      },
      "source": [
        "plt.plot(avg_train_loss_history,label = \"Train\")\r\n",
        "plt.plot(avg_test_loss_history , label = \"Test\")\r\n",
        "plt.title('LOSS PER EPOCH')\r\n",
        "plt.xlabel(\"EPOCHS\")\r\n",
        "plt.ylabel(\"LOSS\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1tUFG5HL2jK"
      },
      "source": [
        "plt.plot(avg_train_accuracy_history , label = \"Train\")\r\n",
        "plt.plot(avg_test_accuracy_history , label = \"Test\")\r\n",
        "plt.title('ACCURACY PER EPOCH')\r\n",
        "plt.xlabel(\"EPOCHS\")\r\n",
        "plt.ylabel(\"ACCURACY\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}